<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>ERF2025 - WS42</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<span class="logo"><img src="images/erf2025_logo.jpg" alt="" /></span>
						<h1>Advancing AI-Powered Robotic Cognition, Deliberation and Learning for Real-World Applications</h1>
						<p>EUROPEAN ROBOTICS FORUM 2025 - WORKSHOP 42<br />
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="#program" class="active">Program</a></li>
							<li><a href="#scope">Scope</a></li>
							<li><a href="#organizers">Organizers</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Introduction -->
							<section id="program" class="main">
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2>Program</h2>
										</header>

										<h3>Workshop Overview</h3>

										<p>
											<strong>Topic 1: High-Level Learning, Task-Level Learning, and Deliberation</strong><br>
											<div>
												<div style="text-align: center; margin-bottom: 20px;">
													<img src="images/francisco.jpeg" alt="Francisco Martín Rico" style="width: 150px; height: 150px; border-radius: 50%;"><br>
													<strong>Francisco Martín Rico</strong>, Rey Juan Carlos University, ES<br>
													<i>Title:</i> Plan Replanning and Repair at PlanSys2<br>
													<i>Abstract:</i> PlanSys2 is the reference planning framework in ROS 2. It combines classical planning with Behavior Trees to execute plans on real robots. However, replanning in such frameworks is typically limited to canceling the current plan and generating a new one from scratch. In this talk, we will explore alternative approaches for adapting to changes in conditions or goals, focusing on repairing the current plan to align with the new situation. We will discuss how various strategies, including the use of Large Language Models (LLMs) to assist in this task, can enhance the efficiency of plan execution.
												</div>
												<div style="text-align: center; margin-bottom: 20px;">
													<img src="images/richard.gif" alt="Richard J. Duro" style="width: 150px; height: 150px; border-radius: 50%;"><br>
													<strong>Richard J. Duro</strong>, Universidad Coruña, ES<br>
													<i>Title:</i> The Purpose Framework: A Path to Useful Autonomous Robots<br>
													<i>Abstract:</i> This talk will introduce the main issues that are being addressed in the PILLAR-Robots project related to Lifelong Open-ended Learning Autonomy (LOLA). PILLAR-Robots seeks to create the basis for developing a new generation of robots endowed with a higher level of autonomy, able to determine their own goals and strategies creatively building on the experience acquired during their lifetime to fulfil the desires of their designers/users in real-life application use-cases. The concept of Purpose, drawn from the cognitive sciences, is operationalized to increase the autonomy and domain independence of robots during autonomous learning, leading them to acquire knowledge and skills that are actually relevant for operating in target real applications. In particular, the talk will describe the purpose framework that has been developed as an integrated motivational structure that supports algorithms for the acquisition of purpose by the robot, ways to bias the perceptual, motivational and decision systems of the robots’ cognitive architectures towards purposes, and strategies for learning representations, skills and models that allow the execution of purpose-related deliberative and reactive decisions. These ideas are being applied in three different application fields characterized by different types and levels of variability: Agri-food, Edutainment, and unstructured Industrial/retail.

												</div>
												<div style="text-align: center; margin-bottom: 20px;">
													<img src="images/christian.jpg" alt="Christian Henkel" style="width: 150px; height: 150px; border-radius: 50%;"><br>
													<strong>Christian Henkel</strong>, Bosch Research, DE<br>
													<i>Title:</i> How we tell the robot what to do? Deliberation in CONVINCE<br>
													<i>Abstract:</i> In this workshop talk, we explore the question: How do we tell a robot what to do? focusing on deliberation within the CONVINCE project. Deliberation, also known as task-planning or mission-planning, is essential for enabling robots to operate autonomously and adaptively in dynamic environments.
													<br>
													We will present the tools and approaches developed in CONVINCE, including formal methods, machine learning, and anomaly detection, and discuss how these support robust decision-making. Drawing from insights gained through the Deliberation Working Group and a ROSCon workshop, we will address key open questions:
													<br>
													What do users need to enable effective robot autonomy?
													How does deliberation differ from traditional industrial robot programming?
													How can we balance low-code solutions with flexible configuration?
													How do we ensure explainability and interpretability, aligning with Industry 5.0 principles?
													This talk aims to engage the audience in a discussion on the unique challenges of modern deliberation, fostering ideas for bridging the gap between robot programming and autonomous behavior.
												</div>
											</div>
										</p>
										
										
										
										<p>
											<strong>Topic 2: Skill-Level Learning and Manipulation</strong><br>
											<div>
												<div style="text-align: center; margin-bottom: 20px;">
													<img src="images/nestor.jpeg" alt="Francisco Martín Rico" style="width: 150px; height: 150px; border-radius: 50%;"><br>
													<strong>Néstor García</strong>, Technology Centre of Catalonia Eurecat, ES<br>
													Title: TBD
												</div>
												<div style="text-align: center; margin-bottom: 20px;">
													<img src="images/dimitrios.jpeg" alt="Richard J. Duro" style="width: 150px; height: 150px; border-radius: 50%;"><br>
													<strong>Dimitrios Giakoumis</strong>, CERTH, GR<br>
													Title: Advancing the Physical Intelligence and Performance of Robots Towards Human-Like Object Manipulation
												</div>
												<div style="text-align: center; margin-bottom: 20px;">
													<img src="images/JoaoSilverio.jpg" alt="Christian Henkel" style="width: 150px; height: 150px; border-radius: 50%;"><br>
													<strong>João Silvério</strong>, German Aerospace Center, DE<br>
													Title: Improving skill learning and generalization via deliberate human inputs
												</div>
											</div>
										</p>

				
									</div>
								</div>
							</section>

						<!-- First Section -->
						<section id="scope" class="main">
							<header class="major">
								<h2>Scope and Objectives</h2>
							</header>
							
							<p style="text-align: justify;">
								This workshop will delve into advanced methods for defining robotic behavior, with a focus on deliberation, adaptability, and real-world applications. Attendees will gain insights from leading projects, including Intelliman, CONVINCE, PILLAR-Robots, euROBIN, and MANIBOT, which are at the forefront of cognitive robotics and AI-powered systems. Key discussions will cover the essentials of robotic deliberation, examining how autonomous, context-aware decision-making can be achieved. Attendees will share input on the requirements for effective deliberation, the challenges faced, and the latest technologies enabling these capabilities.
							</p>
							
							<p style="text-align: justify;">
								The workshop will also explore data-efficient learning and Sim2Real transfer techniques, showcasing approaches to skill acquisition and task planning in unstructured environments. Projects will demonstrate strategies for minimizing data requirements and bridging the gap between simulated and real-world settings. Additionally, we’ll highlight the role of semantic sensor fusion and control theory to enhance robustness and situational awareness in complex tasks. Through collaborative discussions, participants will address both challenges and opportunities in cognitive robotics, aiming to shape the future of AI-powered robots for dynamic, real-world applications.
							</p>
						</section>
						

						<!-- Second Section -->
							<section id="organizers" class="main special">
								
								<header class="major">
									<h2>Organizers</h2>
								</header>
								
								<p>

									<strong>Christian Henkel</strong>, Bosch Research, DE<br>
									<strong>Alessio Caporali</strong>, University of Bologna, IT<br>
									<strong>Roberto Meattini</strong>, University of Bologna, IT<br>
									<strong>Néstor García</strong>, Eurecat, ES<br>
									<strong>Dimitra Triantafyllou</strong>, CERTH, GR<br>
								</p>

							</section>



					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>